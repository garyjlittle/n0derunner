<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>linux-profiling-gprof</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="mvp.css" />
</head>
<body>
<h1 id="working-with-gprof">Working with gprof</h1>
<!-- TOC start (generated with https://github.com/derlin/bitdowntoc) -->

<ul>
<li><a href="#what-can-be-derived-from-a-profile">What can be derived
from a profile</a></li>
<li><a href="#what-is-the-overhead-of-profiling">What is the overhead of
profiling</a></li>
<li><a href="#how-does-profiling-work">How does profiling work</a></li>
<li><a href="#how-to-tell-if-profiling-is-enabled">How to tell if
profiling is enabled</a></li>
<li><a href="#how-to-generate-a-profile">How to generate a
profile</a></li>
<li><a href="#how-to-read-the-profile">How to read the profile</a></li>
<li><a href="#appendices">Appendices and supporting data</a>
<ul>
<li><a href="#how-to-check-if-a-binary-has-profiling-enabled">How to
check if a binary has profiling enabled?</a></li>
<li><a href="#how-are-mcount-and-monstartup-used">How are
<code>mcount</code> and <code>monstartup</code> used to create the
profile?</a></li>
<li><a href="#examples-of-overhead">Some examples of profiling overhead
with different function "sizes"</a></li>
<li><a
href="#lowering-the-impact-of-profiling-with-compiler-optimization">Lowering
the impact of profiling with compiler optimization</a></li>
<li><a href="#test-program-simpler_caller">Test program
(simple_caller.c)</a></li>
<li><a href="#test-makefile">Test makefile</a></li>
</ul></li>
</ul>
<h2 id="gprof-cheat-sheet">gprof cheat sheet</h2>
<h4 id="compiling-with-profiling-enabled">Compiling with profiling
enabled</h4>
<p>Add the switch <code>-pg</code> to have gcc insert the appropriate
code to enable profiling at the compile/link stage.</p>
<h4 id="checking-for-a-profile-enabled-build">Checking for a profile
enabled build</h4>
<p>Run <code>nm &lt;binary&gt; | grep 'mcount'</code> which will tell
you if the profiling functions are present in the build.</p>
<h4 id="compiling-with-optimizations">Compiling with optimizations</h4>
<p>gprof relies on function calls being made so that
<code>_mcount</code> can keep track of them. Some kinds of optimization
will eliminate function calls to speed up execution. When this occurs
the overhead of profiling decreases - but the profile is mainly useless.
Some optimizations I experimented with</p>
<ul>
<li><code>-O</code> does not eliminate function calls (but does speed up
execution a bit)</li>
<li><code>-Ofast</code> does eliminate function calls. Execution is sped
up, but the profile is pretty useless.</li>
</ul>
<h4 id="running-with-profiling-enabled">Running with profiling
enabled</h4>
<p>When a binary is executed that has been built with the
<code>-pg</code> option to gcc - it will generate a
<code>gmon.out</code> file as long as the process exits cleanly.
Depending on signal handlers - a process may not write out a gmon.out
file if it does not exit cleanly.</p>
<h4 id="running-gprof">Running gprof</h4>
<p><code>gprof</code> is the thing that looks at gmon.out and the
compiled binary and produces a text output containing the flat-profile
and the call-graph.</p>
<ul>
<li>Run <code>gprof &lt;binary-compiled-with-gprof</code> ; this will
implicitly use <code>gmon.out</code></li>
<li>Run
<code>gprof &lt;binary-compiled-with-gprof&gt; &lt;profile-datafile-gmon.out-by-default&gt;</code>
<ul>
<li>There is nothing stopping you from running gprof against a
<code>gmon.out</code> and a <binaryfile> that are totally unrelated. If
the functions/symbols make no sense, then this is probably what's
happening.</li>
</ul></li>
</ul>
<h2 id="what-can-be-derived-from-a-profile">What can be derived from a
profile</h2>
<p>A profile can be used to tell a performance analyst which functions
are called (who calls whom) within a particular program and how long was
spent in each function. The call-graph is generated by calling
<code>_mcount</code> every time a function is called. The time spent in
each function is generated by <code>__monstartup</code> which programs
an interrupt to sample the PC.</p>
<h2 id="what-is-the-overhead-of-profiling">What is the overhead of
profiling</h2>
<p>The overhead of profiling depends on the ratio of function calls to
the amount of work performed in each function. Since we call
<code>__mcount</code> on every function call - there is cost per
function call. For instance if each function does a small amount of work
- the overhead will be high. However if each function does a LOT of work
- and relatively few calls/returns relative to the overall work - then
the overhead will be low.</p>
<ul>
<li>High Overhead (Overall runtime is 2X or more)</li>
<li>Low Overhead (Overall runtime is within 1%)</li>
</ul>
<h2 id="how-does-profiling-work">How does profiling work</h2>
<p>We get a profile by building a binary via gcc with "profiling
enabled" - we do that with the <code>-pg</code> option to
<code>gcc</code>.</p>
<p>When we do this, <code>gcc</code> adds a few things to the compiled
binary</p>
<ul>
<li>A call to the function <code>__mcount</code> each time a function is
called (this is what generates the call graph and counts of the
calls)</li>
<li>A call to the function <code>__monstartup</code> at the beginning of
the program (this is what generates the sampling of the PC)</li>
</ul>
<p>Then, when we run the program, a file is generated called
<code>gmon.out</code> which contains data about the running program such
as which functions call other functions and an estimate of how much time
was spent in each function. It is an estimate because the PC is sampled
- but the time spent in each function should be correct relatively. We
can then read the <code>gmon</code> file by using the tool
<code>gprof</code>.</p>
<h2 id="how-to-tell-if-profiling-is-enabled">How to tell if profiling is
enabled</h2>
<p>For any given binary we can tell if profiling is enabled by searching
the binary for the symbols <code>__mcount</code> and
<code>__monstartup</code> using <code>nm</code>.</p>
<h2 id="how-to-generate-a-profile">How to generate a profile</h2>
<p>A profile is generated in three steps</p>
<ol type="1">
<li>Compile the binary with the flag <code>-pg</code></li>
<li>Run the binary - after execution finished the file
<code>gmon.out</code> is written to the PWD</li>
<li>Run the <code>gprof</code> tool - you will need to point it at the
binary file that was running AND <code>gmon.out</code></li>
</ol>
<h2 id="how-to-read-the-profile">How to read the profile</h2>
<ul>
<li>Flat profile <a href="#flat-profile">Example Flat Profile</a></li>
<li>Call Graph <a href="#call-graph">Example Call Graph</a></li>
</ul>
<h2 id="appendices">Appendices</h2>
<ul>
<li><a href="#how-to-check-if-a-binary-has-profiling-enabled">How to
check if a binary has profiling enabled?</a></li>
<li><a href="#how-are-mcount-and-monstartup-used">How are
<code>mcount</code> and `monstartup used?</a></li>
<li><a href="#examples-of-overhead">Some examples of profiling overhead
with different function "sizes"</a></li>
<li><a
href="#lowering-the-impact-of-profiling-with-compiler-optimization">Lowering
the impact of profiling with compiler optimization</a></li>
<li><a href="#test-program-simpler_caller">Test program
(simple_caller.c)</a></li>
<li><a href="#test-makefile">Test makefile</a></li>
</ul>
<h3 id="how-to-check-if-a-binary-has-profiling-enabled">How to check if
a binary has profiling enabled</h3>
<p>e.g. for my binary called <code>simple_caller</code>. If these
symbols are part of the binary - then the binary was built using the
<code>-pg</code> option and it will generate a <code>gmon.out</code>
file.</p>
<pre><code>$ nm simple_caller_pg | egrep &quot;monstart|mcount&quot;
                 U mcount@GLIBC_2.2.5
                 U __monstartup@GLIBC_2.2.5</code></pre>
<p>The filetype of <code>gmon.out</code> is as follows</p>
<pre><code>$ file gmon.out 
gmon.out: GNU prof performance data - version 1</code></pre>
<h3 id="how-are-mcount-and-monstartup-used">How are mcount and
monstartup used</h3>
<p>We can use <code>objdump -d</code> to see the assembly language for
our file - when profiling is enabled we will see the calls to the
special profiling functions (<code>mcount</code> and
<code>monstartup</code>) from our <code>simple_caller</code> file
including main</p>
<h4 id="counting-stack-frames-and-callers-with-mcount">Counting stack
frames and callers with mcount</h4>
<pre><code>$ objdump -d simple_caller_pg
...
000000000000126b &lt;calcme1&gt;:
    126b:       f3 0f 1e fa             endbr64
    126f:       55                      push   %rbp
    1270:       48 89 e5                mov    %rsp,%rbp
    1273:       48 83 ec 20             sub    $0x20,%rsp
    1277:       ff 15 6b 2d 00 00       call   *0x2d6b(%rip)        # 3fe8 &lt;mcount@GLIBC_2.2.5&gt;
...
00000000000012e5 &lt;calcme2&gt;:
    12e5:       f3 0f 1e fa             endbr64
    12e9:       55                      push   %rbp
    12ea:       48 89 e5                mov    %rsp,%rbp
    12ed:       48 83 ec 40             sub    $0x40,%rsp
    12f1:       ff 15 f1 2c 00 00       call   *0x2cf1(%rip)        # 3fe8 &lt;mcount@GLIBC_2.2.5&gt;
...
 0000000000001391 &lt;spinloop&gt;:
    1391:       f3 0f 1e fa             endbr64
    1395:       55                      push   %rbp
    1396:       48 89 e5                mov    %rsp,%rbp
    1399:       48 83 ec 20             sub    $0x20,%rsp
    139d:       ff 15 45 2c 00 00       call   *0x2c45(%rip)        # 3fe8 &lt;mcount@GLIBC_2.2.5&gt;
...
000000000000141b &lt;main&gt;:
    141b:       f3 0f 1e fa             endbr64
    141f:       55                      push   %rbp
    1420:       48 89 e5                mov    %rsp,%rbp
    1423:       48 83 ec 40             sub    $0x40,%rsp
    1427:       ff 15 bb 2b 00 00       call   *0x2bbb(%rip)        # 3fe8 &lt;mcount@GLIBC_2.2.5&gt;
    142d:       48 c7 45 e0 00 00 00    movq   $0x0,-0x20(%rbp)</code></pre>
<h4 id="setting-up-pc-sampling-with-monstartup">Setting up PC sampling
with monstartup</h4>
<pre><code>Disassembly of section .init:

0000000000001000 &lt;_init&gt;:
    1000:       f3 0f 1e fa             endbr64
    1004:       48 83 ec 08             sub    $0x8,%rsp
    1008:       48 8d 05 21 01 00 00    lea    0x121(%rip),%rax        # 1130 &lt;__gmon_start__&gt;
    100f:       48 85 c0                test   %rax,%rax
    1012:       74 02                   je     1016 &lt;_init+0x16&gt;
    1014:       ff d0                   call   *%rax
    1016:       48 83 c4 08             add    $0x8,%rsp
    101a:       c3                      ret
...
0000000000001130 &lt;__gmon_start__&gt;:
    1130:       f3 0f 1e fa             endbr64
    1134:       8b 05 d6 2e 00 00       mov    0x2ed6(%rip),%eax        # 4010 &lt;__TMC_END__&gt;
    113a:       85 c0                   test   %eax,%eax
    113c:       74 02                   je     1140 &lt;__gmon_start__+0x10&gt;
    113e:       c3                      ret
    113f:       90                      nop
    1140:       48 83 ec 08             sub    $0x8,%rsp
    1144:       48 8d 35 f2 04 00 00    lea    0x4f2(%rip),%rsi        # 163d &lt;etext&gt;
    114b:       48 8d 3d ae ee ff ff    lea    -0x1152(%rip),%rdi        # 0 &lt;__executable_start&gt;
    1152:       c7 05 b4 2e 00 00 01    movl   $0x1,0x2eb4(%rip)        # 4010 &lt;__TMC_END__&gt;
    1159:       00 00 00
    115c:       e8 5f ff ff ff          call   10c0 &lt;__monstartup@plt&gt;
    1161:       48 8b 3d 78 2e 00 00    mov    0x2e78(%rip),%rdi        # 3fe0 &lt;_mcleanup@GLIBC_2.2.5&gt;
...
00000000000010c0 &lt;__monstartup@plt&gt;:
    10c0:       f3 0f 1e fa             endbr64
    10c4:       f2 ff 25 e5 2e 00 00    bnd jmp *0x2ee5(%rip)        # 3fb0 &lt;__monstartup@GLIBC_2.2.5&gt;
    10cb:       0f 1f 44 00 00          nopl   0x0(%rax,%rax,1)</code></pre>
<h3 id="examples-of-overhead">Examples of overhead</h3>
<h4 id="overhead-is-relative-to-the-size-of-the-function">Overhead is
relative to the "size" of the function.</h4>
<p>We can create a test program that loops around and calls a few
functions. We can make each of these functions do a bit of work - that
is also in a loop. By playing with the values of "outerloop" and "inner
loop" we can alter how much time is spent within each function. We can
set these valus such that they have about the same runtime - but have a
very different execution profile.</p>
<ul>
<li>With a high outerloop:innerloop (500M:1) ratio we do a lot of
function calls and not much work inside each function</li>
<li>With a low outerloop:innerlop (10:1) reatio we do only a few
function calls and a lot of work in each function</li>
</ul>
<p>Using our test program ('simple_caller') we can compile an example
binary with two variables</p>
<ol type="1">
<li>The number of times to run the outer loop which calls a set of 3
functions directly</li>
<li>The number of times to spin inside the functions.</li>
</ol>
<p>We can use these two variables to make the binary execute for about
the same amount of time (around 25 seconds).</p>
<ul>
<li>Run1 : Outer loop is 500,000,000 Iterations Inner loop is 1
Iteration - Runtime 0m23.521s</li>
<li>Run2 : Outer loop is Outer loop is 100,000 Iterations Inner loop is
10,000 Iterations - Runtime 0m25.425s</li>
</ul>
<p>The behavior is as follows</p>
<ul>
<li>Run1 makes a lof of function calls - and very little work is done
per call</li>
<li>Run2 makes fewer calls - but each function does more work (more
inner loops)</li>
</ul>
<p>If the primary overhead of profiling is counting the calls with
<code>__mcount</code> then we would expect the runtime delta between the
non-profiled and profiled executions to be much higher in Run1 than
Run2</p>
<h4 id="overhead-runtimes">Overhead runtimes</h4>
<h5 id="run1-lots-of-calls-each-function-does-very-little">Run1 lots of
calls, each function does very little</h5>
<ul>
<li>Run1: Execution time with no profiling 23.5 Seconds</li>
<li>Run1 : Execution time with profiling 42 Seconds</li>
<li>Run1 : <strong>Overhead 42/23 == 1.8X</strong></li>
</ul>
<h5 id="run2-fewer-calls-but-each-function-does-a-lot-of-work">Run2
fewer calls but each function does a lot of work</h5>
<ul>
<li>Run2 : Execution time with no profiling 25.425 Seconds</li>
<li>Run2 : Execution time with profiling 25.470 Seconds</li>
<li>Run2 : <strong>Overhead 25.470/25.425 = 1.002 (0.2%)</strong></li>
</ul>
<p>These results support the hypothesis that the profiling overhead is
mostly based on the to the number of functions called relative to the
work done per call.</p>
<h3 id="profiles-of-run1-and-run2">Profiles of Run1 and Run2</h3>
<p>We can see how the different variables affect the execution of the
program by examinig the profiles - and that is the whole point.</p>
<h4 id="run1-profile">Run1 Profile</h4>
<p>Lots of small function calls - one giveaway here is that of the 7.6
seconds sampled, almost 2 seconds was spent in main which does nothing
much at all apart from calling other functions. Also each call
(<code>self ns/call</code>) is very low.. 4NS per call. Be careful of
the metrics, because in the following profile the time is measured in
uSec - so 1000X different order of magnitude.</p>
<h5 id="flat-profile--run1">Flat profile : Run1</h5>
<pre><code>Flat profile:

Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total           
 time   seconds   seconds    calls  ns/call  ns/call  name    
 25.59      1.96     1.96 500000001     3.92     3.92  spinloop
 25.20      3.89     1.93                             main
 20.23      5.44     1.55 333333334     4.65     6.76  calcme2
 13.77      6.50     1.05 500000001     2.11     2.11  return3
 10.25      7.28     0.79 166666667     4.71     6.82  calcme1
  4.96      7.66     0.38                             _init</code></pre>
<h5 id="call-graph--run1">Call Graph : Run1</h5>
<pre><code>                     Call graph (explanation follows)


granularity: each sample hit covers 4 byte(s) for 0.13% of 7.66 seconds

index % time    self  children    called     name
                                                 &lt;spontaneous&gt;
[1]     95.0    1.93    5.35                 main [1]
                1.55    0.70 333333334/333333334     calcme2 [2]
                1.96    0.00 500000001/500000001     spinloop [3]
                0.79    0.35 166666667/166666667     calcme1 [4]
-----------------------------------------------
                1.55    0.70 333333334/333333334     main [1]
[2]     29.4    1.55    0.70 333333334         calcme2 [2]
                0.70    0.00 333333334/500000001     return3 [5]
-----------------------------------------------
                1.96    0.00 500000001/500000001     main [1]
[3]     25.6    1.96    0.00 500000001         spinloop [3]
-----------------------------------------------
                0.79    0.35 166666667/166666667     main [1]
[4]     14.8    0.79    0.35 166666667         calcme1 [4]
                0.35    0.00 166666667/500000001     return3 [5]
-----------------------------------------------
                0.35    0.00 166666667/500000001     calcme1 [4]
                0.70    0.00 333333334/500000001     calcme2 [2]
[5]     13.8    1.05    0.00 500000001         return3 [5]
-----------------------------------------------
                                                 &lt;spontaneous&gt;
[6]      5.0    0.38    0.00                 _init [6]
-----------------------------------------------</code></pre>
<h4 id="run2-profile">Run2 Profile</h4>
<p>Run2 is the run where the calls do a lot of work - we don't see main
in the list of samples at all. Also each function call is in the order
of 10s of uSec - much more than the profile of Run1</p>
<h5 id="flat-profile--run2">Flat Profile : Run2</h5>
<pre><code>Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total           
 time   seconds   seconds    calls  us/call  us/call  name    
 49.84      1.56     1.56    66668    23.40    23.40  calcme2
 26.52      2.39     0.83   100001     8.30     8.30  spinloop
 13.10      2.80     0.41                             _init
 10.54      3.13     0.33    33333     9.90     9.90  calcme1
  0.00      3.13     0.00   100001     0.00     0.00  return3</code></pre>
<h5 id="call-graph--run2">Call Graph : Run2</h5>
<pre><code>                     Call graph (explanation follows)


granularity: each sample hit covers 4 byte(s) for 0.32% of 3.13 seconds

index % time    self  children    called     name
                                                 &lt;spontaneous&gt;
[1]     86.9    0.00    2.72                 main [1]
                1.56    0.00   66668/66668       calcme2 [2]
                0.83    0.00  100001/100001      spinloop [3]
                0.33    0.00   33333/33333       calcme1 [5]
-----------------------------------------------
                1.56    0.00   66668/66668       main [1]
[2]     49.8    1.56    0.00   66668         calcme2 [2]
                0.00    0.00   66668/100001      return3 [6]
-----------------------------------------------
                0.83    0.00  100001/100001      main [1]
[3]     26.5    0.83    0.00  100001         spinloop [3]
-----------------------------------------------
                                                 &lt;spontaneous&gt;
[4]     13.1    0.41    0.00                 _init [4]
-----------------------------------------------
                0.33    0.00   33333/33333       main [1]
[5]     10.5    0.33    0.00   33333         calcme1 [5]
                0.00    0.00   33333/100001      return3 [6]
-----------------------------------------------
                0.00    0.00   33333/100001      calcme1 [5]
                0.00    0.00   66668/100001      calcme2 [2]
[6]      0.0    0.00    0.00  100001         return3 [6]
-----------------------------------------------</code></pre>
<h3
id="lowering-the-impact-of-profiling-with-compiler-optimization">Lowering
the impact of profiling with compiler optimization</h3>
<p>If part of the cost of profiling is the per-function call cost, then
if we optimize the code using gcc optimizations that inline functions -
we should see a reduction in both the runtime of the un-profiled binary
and the delta in runtime between the un-profiled and profiled binaries.
For now we will do optimization using <code>gcc -Ofast</code></p>
<h4 id="summary">Summary</h4>
<ul>
<li>No Optimization : real 0m23.299s</li>
<li>No Optimization with profiling : real 0m42.057s</li>
<li>With -Ofast Optimization : real 0m18.205s</li>
<li>With -Ofast Optimization + profiling (-pg) : real 0m18.035s</li>
</ul>
<p>So using -Ofast definitely reduces the overhead of profiling by 2X or
more. Unfortunately, the reason is that <code>gcc</code> has inlined the
function (which also speeds up the un-profiled exectution (but not by as
much). Unfortunately inlining the function means that our profile is
sort-of useless.</p>
<h4 id="flat-profile-without-optimization">flat profile without
optimization</h4>
<pre><code>Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total           
 time   seconds   seconds    calls  us/call  us/call  name    
 49.84      1.56     1.56    66668    23.40    23.40  calcme2
 26.52      2.39     0.83   100001     8.30     8.30  spinloop
 13.10      2.80     0.41                             _init
 10.54      3.13     0.33    33333     9.90     9.90  calcme1
  0.00      3.13     0.00   100001     0.00     0.00  return3</code></pre>
<h4 id="flat-profile-with-optimization">flat profile with
optimization</h4>
<pre><code>Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total           
 time   seconds   seconds    calls  Ts/call  Ts/call  name    
 78.70      1.33     1.33                             main
 21.30      1.69     0.36                             _init</code></pre>
<h5 id="timings-for-un-optimized-and-optimized-executions">Timings for
Un-Optimized and Optimized executions</h5>
<p>Un-Optimized, no profile</p>
<pre><code>gary@:~/git/unixfun/simple-call$ time ./simple_caller
Outer loop is 500000000
Inner loop is 1
Outer iteration counter is 500000000
spinloop spun for    500000026 iterations
counter incremented  500000001 times
Last result was      1500000144

real    0m23.299s
user    0m23.280s
sys     0m0.005s</code></pre>
<p>Un-Optimized with profile</p>
<pre><code>gary@:~/git/unixfun/simple-call$ time ./simple_caller_pg
Outer loop is 500000000
Inner loop is 1
Outer iteration counter is 500000000
spinloop spun for    500000026 iterations
counter incremented  500000001 times
Last result was      1500000144

real    0m42.057s
user    0m42.021s
sys     0m0.006s
gary@:~/git/unixfun/simple-call$ time ./simple_caller_opt
Outer loop is 500000000
Inner loop is 1
Outer iteration counter is 500000000
spinloop spun for    500000026 iterations
counter incremented  500000001 times
Last result was      1500000144

real    0m18.205s
user    0m18.188s
sys     0m0.007s
gary@:~/git/unixfun/simple-call$ time ./simple_caller_opt_pg
Outer loop is 500000000
Inner loop is 1
Outer iteration counter is 500000000
spinloop spun for    500000026 iterations
counter incremented  500000001 times
Last result was      1500000144

real    0m18.035s
user    0m18.024s
sys     0m0.004s</code></pre>
<h3 id="test-program-simpler_caller">Test program simpler_caller</h3>
<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;time.h&gt;

/* The variables OUTERLOOP and SPINLOOP
   are epxpected to beset in the makefile */

#ifndef OUTERLOOP
#define OUTERLOOP 500000000
#endif

#ifndef SPINLOOP
#define SPINLOOP 1
#endif

/* Global counter */
long int counter = 0;

long int return3(int f) {
    return(f*3);
}   

long int calcme1(int f,long int numspins) {
    long int i;
    int random=0;
    for (i=0; i &lt; numspins; i++) {
        i=i+1;
        random = rand() % 100;
    }   
    return(return3(f+random));
}

long int calcme2(int f,long int numspins,int *ptr) {
    long int i,res=0;  
    int random=0;
    /* For each time around the spin
       loop read an int from the memory 
       we allocated in main()
    */
    for (i=0; i  &lt; numspins; i++) {
        res=i+ptr[i];
        random = rand() % 100;
    }   
    return(return3(f+res+random));
}

long int spinloop(long int z) {
    counter +=1;
    long i;
    int random=0;
    for (i=0; i &lt; z; i++) {
        i=i+1;
        random = rand() % 100;
    }
    return(counter+random);
}

int main() {
    long int i,res,lastres;
    long int loopcounter=0;
    long int iterations = OUTERLOOP; 
    long int numspins = SPINLOOP;
    int *ptr;

    /* Allocate some memory and write to it
       give our functions some  memory reads
       to work with
    */
    ptr=(int *)malloc(1000000*sizeof(int));
    for (i=0; i&lt;1000000; i++) {
        ptr[i]=rand() % 100;
    }
    printf(&quot;Outer loop is %ld\n&quot;, iterations);
    printf(&quot;Inner loop is %ld\n&quot;, numspins);

    for (i = 0; i &lt;= iterations; i++) {
        // Call calcme1 one in three iterations
        if ((i + 1) % 3 == 0) {
            res=calcme1(i,numspins);
        } else {
        // Call calcme2 two in three iterations
            res=calcme2(i,numspins,ptr);
        }
        // Call spinloop every iteration
        loopcounter=spinloop(numspins);
        lastres=res;
    }
    printf(&quot;Outer iteration counter is %ld\n&quot;, iterations);
    printf(&quot;spinloop spun for    %ld iterations\n&quot;, loopcounter);
    printf(&quot;counter incremented  %ld times\n&quot;, counter);
    printf(&quot;Last result was      %ld\n&quot;, lastres);
    return 0;
}</code></pre>
<h3 id="test-makefile">Test makefile</h3>
<pre><code># Define the compiler and the flags
CC = gcc
CFLAGS = -Wall -g

# Low Overhead
#SPINLOOP   = 10000
#OUTERLOOP  = 100000

# High Overhead
SPINLOOP   = 1
OUTERLOOP  = 500000000

# Create multiple outputs
# 1 - Unoptimized executable - will make the function call using standard calling convention
# 2 - Optimized executable - will make the function call using optimized calling convention (inlined)

# As above but in this case we will use the -pg flag to enable profiling

# Define the target executables
TARGET_BASE = simple_caller
TARGET_PG   = simple_caller_pg
TARGET_OPT  = simple_caller_opt
TARGET_OPT_PG   = simple_caller_opt_pg

# Define the source files
SRCS = simple_caller.c

# Define the object files
OBJS = $(SRCS:.c=.o)
OBJS_PG = $(SRCS:.c=_pg.o)
OBJS_OPT = $(SRCS:.c=_opt.o)
OBJS_OPT_PG = $(SRCS:.c=_pg_opt.o)

# Default target
all: $(TARGET_BASE) $(TARGET_PG) $(TARGET_OPT) $(TARGET_OPT_PG)

# Link the object files to create the executable without profiling
$(TARGET_BASE): $(OBJS)
    $(CC) $(CFLAGS) -o $(TARGET_BASE) $(OBJS)

# Link the object files to create the executable with profiling
$(TARGET_PG): $(OBJS_PG)
    $(CC) $(CFLAGS) -pg -o $(TARGET_PG) $(OBJS_PG)

# Link the object files to create the optimized executable without profiling
$(TARGET_OPT): $(OBJS_OPT)
    $(CC) $(CFLAGS) -Ofast -o $(TARGET_OPT) $(OBJS_OPT)

# Link the object files to create the optimized executable with profiling
$(TARGET_OPT_PG): $(OBJS_OPT_PG)
    $(CC) $(CFLAGS) -Ofast -pg -o $(TARGET_OPT_PG) $(OBJS_OPT_PG)

# Compile the source files into object files without profiling
%.o: %.c
    $(CC) $(CFLAGS) -DOUTERLOOP=$(OUTERLOOP) -DINNERLOOP=$(INNERLOOP) -c $&lt; -o $@

# Compile the source files into object files with profiling
%_pg.o: %.c
    $(CC) $(CFLAGS) -DOUTERLOOP=$(OUTERLOOP) -DINNERLOOP=$(INNERLOOP) -pg -c $&lt; -o $@

# Compile the source files into optimized object files without profiling
%_opt.o: %.c
    $(CC) $(CFLAGS) -Ofast -DOUTERLOOP=$(OUTERLOOP) -DINNERLOOP=$(INNERLOOP) -c $&lt; -o $@

# Compile the source files into optimized object files with profiling
%_pg_opt.o: %.c
    $(CC) $(CFLAGS) -Ofast -DOUTERLOOP=$(OUTERLOOP) -DINNERLOOP=$(INNERLOOP) -pg -c $&lt; -o $@

# Clean up the build files
clean:
    rm -f $(OBJS) $(OBJS_PG) $(OBJS_OPT) $(OBJS_OPT_PG) $(TARGET_BASE) $(TARGET_PG) $(TARGET_OPT) $(TARGET_OPT_PG)

.PHONY: all clean</code></pre>
<p>When we want to get a profile from gprof we ask <code>gcc</code> to
insert additional code (a function call) into the compiled binary, hence
there is no need for any special hardware support - no issues running
the tool in a VM/container etc whereas some tools need to access the CPU
directly via passthrough, or you need to be root etc.</p>
<h5 id="the-general-workflow-is-as-follows">The general workflow is as
follows</h5>
<p>Build a binary using the flag <code>-pg</code> this will create a
"special" build of your program which implements profiling - the program
should operate as normal, albeit a bit slower. <a
href="https://sourceware.org/binutils/docs/gprof/Implementation.html">the
implementation of profiling is detailed here in the gprof man/help/doc
page</a></p>
<p>There will be an additional symbol/function inserted into the binary
that gcc produces. In the output of <code>nm</code> you will see this
function - it is called <code>mcount</code>. This is the function that
does the work of figuring out which function calls what - so an easy way
to see if a binary has profiling enabled is to look for that symbol.</p>
<p>During compilation/linking <code>gcc</code> inserts calls to
<code>mcount</code> into each function call in the assembly/binary that
it produces for you.</p>
<p>In the output below the symbol <code>counter</code> is just a
variable in my program.</p>
<pre><code>gary:~/git/unixfun/simple-call$ cc -o 1b-pg -pg simple_call_1B.c
gary:~/git/unixfun/simple-call$ nm ./1b-pg |grep count

0000000000004018 B counter
                 U mcount@GLIBC_2.2.5    &lt;----- This binary has profiling enabled

gary:~/git/unixfun/simple-call$ cc -o 1b simple_call_1B.c
gary@:~/git/unixfun/simple-call$ nm ./1b |grep count

0000000000004014 B counter
                                         &lt;------- No mcount, means no profiling</code></pre>
<p>Also in the assembly you will see calls to _mcount. Output from
<code>objdump -d &lt;binary&gt;</code></p>
<pre><code>    1242:       53                      push   %rbx
    1243:       ff 15 9f 2d 00 00       call   *0x2d9f(%rip) # 3fe8 &lt;mcount@GLIBC_2.2.5&gt;  &lt;----- this is only seen in pg builds
    1249:       bb 00 ca 9a 3b          mov    $0x3b9aca00,%ebx</code></pre>
<ul>
<li>When you run the binary compiled with <code>-pg</code> it will
create a binary output file called <code>gmon.out</code> in the currenty
working directory.</li>
<li>Then use the <code>gprof</code> tool to read the gmon.out - it needs
to reference the binary (compiled with pg) to show the right
symbols/functions etc. In our example below for the binary compiled with
profiling. After the run completes - issue <code>gprof 1b-pg</code> and
the gprof command will read the file gmon.out and use the symbols in the
binary to display the correct function names.</li>
</ul>
</body>
</html>
